---
title: "Gen G"
date: "`r Sys.Date()`"
output: html_document
# output:
#   tufte::tufte_html: default
#   tufte::tufte_handout:
#     citation_package: natbib
#     latex_engine: xelatex
#   tufte::tufte_book:
#     citation_package: natbib
#     latex_engine: xelatex
---

```{r setup, include=FALSE}
#devtools::install_github("ricardo-bion/ggradar", dependencies = TRUE)
library(tufte)
library(knitr)
library(twitteR)
library(ROAuth)
library(hms)
library(lubridate) 
library(tidytext)
library(tidyverse)
library(forcats)
library(tm)
library(wordcloud)
library(igraph)
library(glue)
library(networkD3)
library(rtweet)
library(stringr)
library(ggplot2)
library(ggthemes)
library(ggeasy)
library(plotly)
library(hms)
library(magrittr)
library(widyr)
library(wordcloud2)
library(showtext)
library(ragg)
library(scales)
library(ggradar)
library(sf)
library(leaflet)
library(stringi)
library(nsyllable)
library(MLmetrics)
library(koRpus)

# The JRB custom palette based on a photo I took in Owens Valley, California:
ov_colors <- c(
  `teal`       = "#3e747a",
  `darkblue`   = "#2e4263",
  `royalblue` = "#5056b6",
  `blue`     = "#4b8ce8",
  `skyblue`   = "#7ec8f7",
  `brown` = "#94855e",
  `yellow`  = "#fedf25",
  `rust` = "#ad6343",
  `brownn` = "#533721",
  `redbrown` = "#784146",
  `earth` = "#a4545f"
)

ov_cool <-
  c("#3e747a",
    "#2e4263",
    "#5056b6",
    "#4b8ce8",
    "#7ec8f7",
    "#94855E")

ov_cols <- function(...) {
  cols <- c(...)
  
  if (is.null(cols))
    return (ov_colors)
  
  ov_colors[cols]
}

ov_palettes <- list(
  `main`  = ov_cols(
    "teal",
    "darkblue",
    "royalblue",
    "blue",
    "skyblue",
    "brown",
    "yellow",
    "rust",
    "brownn",
    "redbrown",
    "earth"
  ),
  
  `cool`  = ov_cols("teal", "darkblue", "royalblue", "blue", "skyblue", "brown"),
  
  `choro` = ov_cols("skyblue", "blue", "darkblue", "brownn")
)

ov_pal <- function(palette = "main",
                   reverse = FALSE,
                   ...) {
  pal <- ov_palettes[[palette]]
  
  if (reverse)
    pal <- rev(pal)
  
  colorRampPalette(pal, ...)
}


scale_color_ov <-
  function(palette = "main",
           discrete = TRUE,
           reverse = FALSE,
           ...) {
    pal <- ov_pal(palette = palette, reverse = reverse)
    
    if (discrete) {
      discrete_scale("colour", paste0("ov_", palette), palette = pal, ...)
    } else {
      scale_color_gradientn(colours = pal(256), ...)
    }
  }

scale_fill_ov <-
  function(palette = "main",
           discrete = TRUE,
           reverse = FALSE,
           ...) {
    pal <- ov_pal(palette = palette, reverse = reverse)
    
    if (discrete) {
      discrete_scale("fill", paste0("ov_", palette), palette = pal, ...)
    } else {
      scale_fill_gradientn(colours = pal(256), ...)
    }
  }

# read in data:
gen_text = read.csv('/Users/jrb/Desktop/R/Gen_G.csv')
```

Text in this document is from both speeches, and written remarks. All text is unclassified.

## Sentiment Scores

Tokenized words (not including stopwords), mapped to sentiment, and plotted by frequency. Sentiments come from the NRC dictionary. Plot includes all unclassified written text from March 2024 to June 2025.

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height= 8, fig.width=10}
word2<-gen_text

docs <-
  tm::VCorpus(tm::VectorSource(word2$text), readerControl = list(language = "en"))

toSpace <-
  content_transformer(function (x , pattern)
    gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")

# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("en"))

# specify stopwords as a character vector
docs <-
  tm_map(
    docs,
    removeWords,
    c(
      "the",
      "and",
      "pur",
      "her",
      "his",
      "were",
      "she",
      "he",
      "him",
      "could",
      "which",
      "when",
      "did",
      "had",
      "went",
      "they",
      "any",
      "because",
      "ani",
      "also",
      "been",
      "them",
      "than",
      "has",
      "very",
      "have",
      "per",
      "does",
      "within",
      "get",
      "north",
      "usnorthcom",
      "norad",
      "will"
    )
  ) 

# Remove punctuation
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)

dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m), decreasing = TRUE)
d <- data.frame(word = names(v), freq = v)

nrc <- get_sentiments("nrc")

b <- d %>%
  inner_join(nrc, by = c(word = "word")) %>%
  distinct(word, .keep_all = T) %>%
  dplyr::slice_max(freq, n = 46)

# the plot:
ggplot(data = b,
       aes(
         x = word,
         y = freq,
         label = freq,
         #color = sentiment,
         fill = sentiment
       )) +
  geom_col(position = 'dodge') +
  coord_flip() +
  facet_wrap( ~ sentiment, scales = "free") +
  # geom_text(aes(label = freq),
  #           position = position_dodge(width = 0.9),
  #           hjust = -0.10,
  #           size = 3) +
  scale_fill_manual(
    values = c(
      "anticipation" = "#fedf25",
      "positive" = "#3e747a",
      "joy" = "#7ec8f7",
      "fear" = "#94855e",
      "trust" = "#5056b6",
      "negative" = "#ad6343",
      "sadness" = "#2e4263",
      "disgust" = "#a4545f",
      "anger" = "#784146",
      "surprise" = "#533721"
    )
  ) +
  ggthemes::theme_tufte() +
  theme(
    legend.position = "none",
    axis.text.x = element_text(size = 10),
    axis.text.y = element_text(size = 10),
    axis.title.y = element_text(size = 12),
    axis.title.x = element_text(size = 12),
    plot.title = element_text(size = 14),
    strip.text.x = element_text(size = 12),
    panel.background = element_rect(fill = "#fffff8", color = "#fffff8"),
    plot.background = element_rect(fill = "#fffff8")
  ) +
  labs(
    title = paste("Most Used Words by Count, and their Sentiments", sep = " "),
    x = paste("Top 46 Words"),
    y = "Count"
  )
```

## Wordcloud

Plot does not include stopwords. Additionally, "NORAD", and "NORTHCOM" are not included.This plot represents all text combined. 

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height= 8, fig.width=10}
# changed "Corpus" to "VCorpus"
set.seed(1234)

wordcloud::wordcloud(
  words = d$word,
  freq = d$freq,
  min.freq = 1,
  max.words = 30,
  random.order = FALSE,
  rot.per = 0.35,
  colors = ov_colors,
  vfont=c("serif","plain")
)

```

## Radar

`r tufte::newthought('Radar plot is based on NRC sentiment dictionary.')` The plot shows language choices overwhelmingly focused on "positive" words, while "fear", and "trust" sentiments followed. Stong "positive" sentiment led.

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height= 8, fig.width=10}
no<-word2 %>%
  unnest_tokens(word, text)

no_nrc<-inner_join(no, nrc, by=c("word"="word"))

# all the data:
no_nrc<-no_nrc %>%
  select(sentiment) %>% # word, location, account_created_at) %>%
  group_by(sentiment) %>%
  count() %>%
  ungroup() %>%
  #mutate_at(vars(-sentiment), rescale) %>%
  pivot_wider(names_from = "sentiment", values_from = "n")

ggradar(no_nrc,
        grid.min = 0,
        grid.max = max(no_nrc),
        group.colours = "#4b8ce8",
        fill = T,
        font.radar = "serif",
        group.point.size = 2.5,
        values.radar = c(min(no_nrc), mean(no_nrc), max(no_nrc)),
        label.gridline.max = T,
        label.gridline.mid = T,
        grid.mid = mean(no_nrc)) +
  theme(plot.title = element_text(hjust = 0.5), panel.background = element_rect(fill = "#fffff8", color = "#fffff8"),
        plot.background = element_rect(fill = "#fffff8")) +
  labs(title = )
```

## Bar Chart of Sentiment Over Time

The bar chart represents percentages of NRC sentiments expressed in unclassified text over time. 

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height= 8, fig.width=10}
# all the datas:
ov_colors <-
  c(
    "#3e747a",
    "#2e4263",
    "#5056b6",
    "#4b8ce8",
    "#7ec8f7",
    "#94855e",
    "#fedf25",
    "#ad6343",
    "#533721",
    "#784146",
    "#a4545f"
  )

no_nrc<-inner_join(no, nrc, by=c("word"="word"))

dat <- no_nrc %>%
  group_by(date, sentiment) %>%
  count(sentiment) %>%
  ungroup() %>%
  group_by(date) %>%
  mutate(Average = (n/sum(n))*100) 

dat %>%
  ggplot(aes(x = as.factor(mdy(date)), y = Average, fill = sentiment)) +
  geom_col(show.legend = T) +
  labs(x="Date", y="Sentiment Percent") +
  theme_tufte() +
  theme(panel.background = element_rect(fill = "#fffff8", color = "#fffff8"),
        plot.background = element_rect(fill = "#fffff8")) +
  scale_fill_manual(values = ov_colors)
  #coord_flip()

```

## Term Frequency - Inverse Document Frequency

`r tufte::newthought('TF - IDF measures the importance of words')` across documents using two measurements: the number of times a word appears in a document, and the inverse frequency a word appears across a set of documents. The tf-idf score is calculated by multiplying the number of times a word appears in a document (adjusted for document length) by the inverse document frequency. The closer to 0 times a word appears across documents, the more important that word is presumed to be. The resulting score is the tf-idf score, and the higher the score, the more important the word is presumed to be. 

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height= 8, fig.width=10}
gen_words <- gen_text %>%
  group_by(text, date) %>%
  unnest_tokens(specific_text, text) %>%
  count(specific_text, sort = TRUE)

total_words <- gen_words %>%
  group_by(date) %>%
  summarize(total = sum(n))

all_the_words <- left_join(gen_words, total_words)

all_the_words <- all_the_words %>%
  tidytext::bind_tf_idf(term = specific_text, document = date, n = n) %>%
  arrange(-tf_idf) %>%
  mutate(word=factor(specific_text, levels=rev(unique(specific_text)))) %>%
  ungroup() %>%
  slice(1:30) %>%
  arrange(tf_idf)

options(scipen=999)

ggplot(all_the_words, aes(tf_idf, word, fill=word)) +
  geom_col(show.legend = F) +
  scale_fill_ov(palette = "cool") +
  theme_tufte() +
  theme(
    axis.text.x = element_text(size = 10),
    axis.text.y = element_text(size = 10),
    axis.title.y = element_text(size = 12),
    axis.title.x = element_text(size = 12),
    plot.title = element_text(size = 16),
    strip.text.x = element_text(size = 12),
    panel.background = element_rect(fill = "#fffff8", color = "#fffff8"),
    plot.background = element_rect(fill = "#fffff8")
  ) 
  # labs(title = paste("tf - idf Analysis of", hashtag, "compared to", hashtag_ru, sep = " "), x = "10 highest scoring terms",
  #      y = "tf - idf score")


```

## Mendenhall's Characteristic Curves of Composition

Character count in words by the same author over time shows little change.

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height= 8, fig.width=10}
# tokenize; use "gen_words" from the word cloud
p <- gen_words %>%
  mutate(Character_count = nchar(specific_text), .keep = "all") %>%
  #group_by(date) %>%
  #mutate(average_characters = mean(Character_count), .keep = "all") %>%
  ungroup() %>%
  group_by(date, Character_count) %>%
  count() %>%
  ungroup() %>%
  mutate(z_scores = ((Character_count-mean(Character_count)))/sd(Character_count), .keep = "all")

p$date <- as.factor(p$date)

ggplot(p) +
  geom_point(aes(x = Character_count, y = n, color = date)) +
  geom_line(aes(x = Character_count, y = n, color = date)) +
  geom_vline(aes(xintercept = mean(Character_count), color = date)) +
  theme_tufte() +
  theme(
    panel.background = element_rect(fill = "#fffff8", color = "#fffff8"),
    plot.background = element_rect(fill = "#fffff8")
  ) +
  scale_color_manual(values = ov_colors) +
  scale_x_discrete(limits = c(0:18))
```

## As Z Scores

This plot show, by date, the z score calculations (difference from the mean) of character counts in words.

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height= 8, fig.width=10}
# as z scores
ggplot(p) +
  geom_point(aes(x = Character_count, y = (z_scores)*n, color = date)) +
  geom_line(aes(x = Character_count, y = (z_scores)*n, color = date)) +
  theme_tufte() +
  theme(
    panel.background = element_rect(fill = "#fffff8", color = "#fffff8"),
    plot.background = element_rect(fill = "#fffff8")
  ) +
  scale_color_manual(values = ov_colors) +
  scale_x_discrete(limits = c(0:18))

```

## FKGL, Reading Ease

Flesh-Kincaid Grade Level scores range from 0 to 18 (higher means more complicated to read). Reading Ease scores range from 0 to 100 (higher means easier to read).

FKGL scores between 7.0 and 8.0 indicate an average adult can read easily. Average FKGL over time is 11.55. The FKGL score is trending toward more simple writing.

Reading Ease scores below 60 indicate difficulty for most adults. Average Reading Ease score over time is 32.53. The Reading Ease score has trended toward easier readability.

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height= 8, fig.width=10}
gen_text = read.csv('/Users/jrb/Desktop/R/Gen_G.csv')

gen_text$sentences <-
  stri_count_fixed(gen_text$text, ".") + stri_count_fixed(gen_text$text, "?") +
  stri_count_fixed(gen_text$text, "!") + stri_count_fixed(gen_text$text, ".")

gen_text$words <- stri_count_words(gen_text$text)

gen_text$syllables <- nsyllable(x = gen_text$text, language = "en", syllable_dictionary = NULL, use.names = FALSE)

# Calculate Flesch-Kincaid Readability
gen_text <- gen_text %>%
  mutate(Reading_Ease = (206.835 - 1.015 * (gen_text$words / gen_text$sentences) - 84.6 *
  (gen_text$syllables / gen_text$words))) %>%
  mutate(FKGL = (0.39 * (gen_text$words / gen_text$sentences) + 11.8 * (gen_text$syllables
                                                       / gen_text$words) - 15.59))

gen_text$date <- mdy(gen_text$date)

ggplot(gen_text) +
  geom_point(
    aes(
      x = date,
      y = FKGL,
      fill = "#3E747A"
    ),
    shape = 21,
    size = 10,
    alpha = .5
  ) +
  geom_smooth(
    aes(
      x = date,
      y = FKGL,
      color = form
      #fill = "#3E747A"
    ),
    #color = "#3E747A",
    method = lm,
    se = FALSE,
    alpha = .5
  ) +
  geom_point(
    aes(
      x = date,
      y = Reading_Ease,
      fill = "#4b8ce8"
    ),
    shape = 21,
    size = 10,
    alpha = .5
  ) +
  geom_smooth(
    aes(
      x = date,
      y = Reading_Ease,
      color = form
      #fill = "#4b8ce8"
    ),
    #color = "#4b8ce8",
    method = lm,
    se = FALSE,
    alpha = .5
  ) +
  theme_tufte() +
  theme(
    legend.position = "right",
    plot.background = element_rect(fill = "#fffff8"),
    axis.text.x = element_text(
      angle = 90,
      vjust = 1,
      hjust = 1
    ),
  ) +
  xlab("Date") +
  ylab("FKGL & Reading Ease Scores") +
  scale_fill_manual(
    values = c("#3E747A", "#4b8ce8"),
    labels = c("FKGL", "Reading Ease")
  ) +
  guides(fill = guide_legend(title = ""))
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height= 8, fig.width=10, eval=FALSE}
# Other counts:
ggplot(gen_text) +
  geom_point(
    aes(
      x = date,
      y = sentences,
      fill = "#3E747A"
    ),
    shape = 21,
    size = 8,
    alpha = .8
  ) +
  geom_smooth(
    aes(
      x = date,
      y = sentences,
      fill = "#3E747A"
    ),
    color = "#3E747A",
    method = lm,
    se = FALSE
  ) +
  geom_point(
    aes(
      x = date,
      y = words,
      fill = "pink"
    ),
    shape = 21,
    size = 8,
    alpha = .8
  ) +
  geom_smooth(
    aes(
      x = date,
      y = words,
      fill = "pink"
    ),
    color = "pink",
    method = lm,
    se = FALSE
  ) +
  geom_point(
    aes(
      x = date,
      y = syllables,
      fill = "red"
    ),
    shape = 21,
    size = 8,
    alpha = .8
  ) +
  geom_smooth(
    aes(
      x = date,
      y = syllables,
      fill = "red"
    ),
    color = "red",
    method = lm,
    se = FALSE
  ) +
  theme_tufte() +
  theme(
    legend.position = "right",
    plot.background = element_rect(fill = "#fffff8"),
    axis.text.x = element_text(
      angle = 90,
      vjust = 1,
      hjust = 1
    ),
  ) +
  xlab("Date") +
  ylab("Counts of Sentences, Words, and Syllables") +
  scale_fill_manual(
    values = c("#3E747A", "pink", "red"),
    labels = c("Sentences", "Words", "Syllables")
  ) +
  guides(fill = guide_legend(title = ""))
```

## Gunning Fog Index

The GFI can confirm that text can be read easily by the intended audience. Texts for a wide audience generally need a fog index less than 12. Texts requiring near-universal understanding generally need an index less than 8.

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height= 8, fig.width=10}
# GFI requires count of sentences, count of syllables, and count of words with 3+ syllables (complex word)

# use gen_words, and add a col that counts words with three or more
gen_words <- gen_text %>%
  group_by(text, date) %>%
  unnest_tokens(specific_text, text) %>%
  count(specific_text, sort = TRUE) %>%
  ungroup()

gen_words$syllables <- nsyllable(x = gen_words$specific_text, language = "en", syllable_dictionary = NULL, use.names = FALSE)

gen_words$if_complex <- ifelse(gen_words$syllables >= 3, "Complex_Word", "Not_Complex_Word")

# need count of words v count of complex words:
j <- gen_words %>%
  group_by(date, if_complex) %>%
  count() %>%
  ungroup() %>%
  pivot_wider(names_from = "if_complex", values_from = "n") %>%
  mutate(total_words = Complex_Word + Complex_Word)

# join j and gen_text by date
gfi <- full_join(gen_text, j, by = "date")

gfi$gunning_fog_index <- 0.4 * ((gfi$words / gfi$sentences) + 100 * (gfi$Complex_Word / gfi$words))

ggplot(gfi) +
  geom_point(
    aes(
      x = date,
      y = gunning_fog_index,
      fill = form
    ),
    shape = 21,
    size = 8,
    alpha = .8
  ) +
  geom_smooth(
    aes(
      x = date,
      y = gunning_fog_index,
      color = form
    ),
    #color = "#3E747A",
    method = lm,
    se = FALSE
  ) +
  theme_tufte() +
  theme(
    legend.position = "right",
    plot.background = element_rect(fill = "#fffff8"),
    axis.text.x = element_text(
      angle = 90,
      vjust = 1,
      hjust = 1
    ),
  ) +
  xlab("Date") +
  ylab("Gunning Fog Index") +
  scale_fill_ov(palette = "choro") +
  #scale_fill_manual(values = c("#C7C07A", "#69A1B4"), labels = c("Testimony", "News Letter")) +
  guides(fill = guide_legend(title = "Index of Readability"))

```

## SMOG

"Simple Measure of Gobbledygook" 5-8 is average, and above 14 is difficult to read.

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height= 8, fig.width=10}
#SMOG = 1.0430 
l <- sqrt(gfi$Complex_Word)+3

gfi <- gfi %>%
  mutate(SMOG = (sqrt(Complex_Word)+3))

ggplot(gfi) +
  geom_point(
    aes(
      x = date,
      y = SMOG,
      fill = form
    ),
    shape = 21,
    size = 8,
    alpha = .8
  ) +
  geom_smooth(
    aes(
      x = date,
      y = SMOG,
      fill = form
    ),
    #color = "#3E747A",
    method = lm,
    se = FALSE
  ) +
  theme_tufte() +
  theme(
    legend.position = "right",
    plot.background = element_rect(fill = "#fffff8"),
    axis.text.x = element_text(
      angle = 90,
      vjust = 1,
      hjust = 1
    ),
  ) +
  xlab("Date") +
  ylab("SMOG Index") +
  scale_fill_ov(palette = "choro") +
  guides(fill = guide_legend(title = "Index of Readability"))
```